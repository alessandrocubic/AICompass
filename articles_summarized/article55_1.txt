Providers of general-purpose AI models that are identified as having systemic risk are subject to additional obligations beyond those specified in Articles 53 and 54. They must conduct model evaluations using standardized protocols and tools that reflect current best practices, including adversarial testing to identify and mitigate systemic risks. Furthermore, they are required to assess and address potential systemic risks at the Union level related to the development, market placement, and use of these models. They must also document and promptly report any serious incidents and corrective measures to the AI Office and relevant national authorities. Lastly, providers must ensure that both the model and its physical infrastructure maintain a sufficient level of cybersecurity protection.