The obligations established in this recital classify certain uses of biometric systems as high-risk due to the special nature of biometric data and the potential for technical inaccuracies in AI systems that perform remote biometric identification. Such inaccuracies can lead to biased outcomes and discriminatory effects, particularly concerning age, ethnicity, race, sex, or disabilities. Consequently, remote biometric identification systems are categorized as high-risk to mitigate these risks. However, AI systems used for biometric verification—aimed solely at confirming an individual's identity for access to services or secure premises—are excluded from this high-risk classification. Additionally, AI systems designed for biometric categorization based on sensitive attributes, as well as emotion recognition systems not prohibited under existing regulations, are deemed high-risk. Conversely, biometric systems intended solely for cybersecurity and personal data protection purposes are not classified as high-risk AI systems. This framework aims to address the complexities and risks associated with biometric data usage while providing clarity on permissible applications.