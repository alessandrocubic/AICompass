Providers of AI systems, including general-purpose systems that generate synthetic audio, images, videos, or text, are required to ensure that their outputs are marked in a machine-readable format, clearly indicating that the content has been artificially generated or manipulated. They must implement technical solutions that are effective, interoperable, robust, and reliable, considering the specific characteristics and limitations of different content types, implementation costs, and current technical standards. However, this obligation does not apply if the AI systems function as assistive tools for standard editing, do not significantly alter the input data or its meaning, or if the use is authorized by law for detecting, preventing, investigating, or prosecuting criminal offenses.